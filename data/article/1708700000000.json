{
  "id": "1708700000000",
  "title": "[26.02.23] Dog Lameness Detection - 시계열모델",
  "content": "<h1>Project1: 반려견 파행 탐지 (Dog Lameness Detection)</h1><h2>1. 프로젝트 개요</h2><p>본 프로젝트는 반려견의 보행 영상에서 추출한 <strong>포즈 데이터(29 keypoints)</strong>를 기반으로, <strong>LSTM+CNN 딥러닝 모델</strong>을 활용하여 파행(lameness)을 자동으로 탐지하고 분류하는 연구입니다.</p><h2>2. 데이터 구성</h2><table style=\"border-collapse:collapse; width:100%; margin:16px 0;\"><thead><tr style=\"background:#f3f4f6;\"><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">구분</th><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">항목</th><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">값</th></tr></thead><tbody><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">학습 데이터</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">출처</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">RTMt ONNX (20250808), ~150+ 환자</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">테스트 데이터</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">출처</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">SNU November (2024.11~2025.01), ~19+ 환자</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">입력</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Keypoints</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">29 keypoints x 2 (x, y) = 58 features</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">입력</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Sequence</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">25 frames (stride=6)</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">전처리</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">정규화</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Bbox 기반 회전 + Min-Max 스케일링 [-1, 1]</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Augmentation</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">좌우 반전</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">L/R keypoint 및 label swap</td></tr></tbody></table><h2>3. 모델 아키텍처</h2><p><strong>VanillaLSTM</strong> (Bidirectional LSTM + Conv1D)</p><pre><code>Input (B, 25, 58)\n  -> Bidirectional LSTM (hidden=32, layers=2, dropout=0.3)\n  -> Dropout(0.5)\n  -> Conv1d (kernel=3, out=16) -> GroupNorm -> ReLU -> Dropout(0.3)\n  -> Global Average Pooling\n  -> FC -> 3 classes</code></pre><h2>4. 학습 설정</h2><table style=\"border-collapse:collapse; width:100%; margin:16px 0;\"><thead><tr style=\"background:#f3f4f6;\"><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">하이퍼파라미터</th><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">값</th></tr></thead><tbody><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Epochs</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">100</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Batch Size</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">64</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Optimizer</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">AdamW (lr=5e-4, weight_decay=1e-3)</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Scheduler</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">ReduceOnPlateau (factor=0.2, patience=10)</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">K-Fold</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">5-fold Stratified</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Loss</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">CrossEntropy (class weight 적용)</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Gradient Clipping</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">max_norm=1</td></tr></tbody></table><hr/><h2>5. 실험 결과</h2><p>총 3회의 실험을 수행하였으며, 실험 모드와 데이터 처리 방식에 따라 구분됩니다.</p><hr/><h3>5-1. Run 1 (Feb23_0130) - Downsample 모드 (초기 버전)</h3><p><strong>실험 설정:</strong> Normal / FR (앞다리 이상) / HI (뒷다리 이상) 3클래스 분류. Normal 다운샘플링 없음.</p><p><strong>Confusion Matrix:</strong></p><img src=\"/api/assets/cm_run1_downsample_initial.png\" alt=\"Run1 Confusion Matrix\" style=\"max-width:100%; margin:12px 0;\"/><table style=\"border-collapse:collapse; width:100%; margin:16px 0;\"><thead><tr style=\"background:#f3f4f6;\"><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">클래스</th><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">Recall</th><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">정분류 / 전체</th></tr></thead><tbody><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Normal</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">28%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">200 / 707</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">FR</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">14%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">37 / 257</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">HI</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">61%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">544 / 890</td></tr><tr style=\"background:#fef3c7;\"><td style=\"border:1px solid #d1d5db; padding:8px 12px;\"><strong>Overall Accuracy</strong></td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\" colspan=\"2\"><strong>42.1% (781 / 1,854)</strong></td></tr></tbody></table><p><strong>분석:</strong> 모델이 HI(뒷다리 이상)으로 편향되어 예측하는 경향이 강함. Normal과 FR의 대부분이 HI로 오분류됨. 클래스 불균형이 주요 원인으로 추정.</p><hr/><h3>5-2. Run 2 (Feb23_0200) - Downsample 모드 (Normal 다운샘플링 적용)</h3><p><strong>실험 설정:</strong> Normal / FR / HI 3클래스. Normal 클래스에 다운샘플링을 적용하여 클래스 균형 개선 시도.</p><p><strong>Confusion Matrix:</strong></p><img src=\"/api/assets/cm_run2_downsample.png\" alt=\"Run2 Confusion Matrix\" style=\"max-width:100%; margin:12px 0;\"/><table style=\"border-collapse:collapse; width:100%; margin:16px 0;\"><thead><tr style=\"background:#f3f4f6;\"><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">클래스</th><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">Recall</th><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">정분류 / 전체</th></tr></thead><tbody><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Normal</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">24%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">216 / 916</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">FR</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">24%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">137 / 574</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">HI</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">74%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">1,124 / 1,509</td></tr><tr style=\"background:#fef3c7;\"><td style=\"border:1px solid #d1d5db; padding:8px 12px;\"><strong>Overall Accuracy</strong></td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\" colspan=\"2\"><strong>49.2% (1,477 / 2,999)</strong></td></tr></tbody></table><p><strong>Per-Sample Prediction (Sliding Window Vote):</strong></p><img src=\"/api/assets/ps_ds_p1.png\" alt=\"Per-sample Downsample p1\" style=\"max-width:100%; margin:12px 0;\"/><img src=\"/api/assets/ps_ds_p2.png\" alt=\"Per-sample Downsample p2\" style=\"max-width:100%; margin:12px 0;\"/><img src=\"/api/assets/ps_ds_p3.png\" alt=\"Per-sample Downsample p3\" style=\"max-width:100%; margin:12px 0;\"/><p><strong>분석:</strong> Run 1 대비 전체 정확도가 42.1% -> 49.2%로 약 7%p 상승. 다운샘플링으로 FR의 recall이 14% -> 24%로 개선되었으나, 여전히 HI 편향이 강하게 존재. Normal과 FR 모두 HI로 오분류되는 패턴이 지속됨.</p><hr/><h3>5-3. Run 3 (Feb23_0215) - HLHR 모드 (뒷다리 좌/우 세분화)</h3><p><strong>실험 설정:</strong> 앞다리(FR) 데이터를 제외하고, 뒷다리 이상을 <strong>HL(뒷다리 왼쪽)</strong>과 <strong>HR(뒷다리 오른쪽)</strong>로 세분화한 3클래스 분류. 좌우 반전 augmentation 시 HL <-> HR 라벨도 함께 swap.</p><p><strong>Confusion Matrix:</strong></p><img src=\"/api/assets/cm_run3_hlhr.png\" alt=\"Run3 Confusion Matrix\" style=\"max-width:100%; margin:12px 0;\"/><table style=\"border-collapse:collapse; width:100%; margin:16px 0;\"><thead><tr style=\"background:#f3f4f6;\"><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">클래스</th><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">Recall</th><th style=\"border:1px solid #d1d5db; padding:8px 12px;\">정분류 / 전체</th></tr></thead><tbody><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Normal</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">52%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">478 / 916</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">HL (뒷다리 왼쪽)</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">50%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">561 / 1,113</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">HR (뒷다리 오른쪽)</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">71%</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">280 / 396</td></tr><tr style=\"background:#d1fae5;\"><td style=\"border:1px solid #d1d5db; padding:8px 12px;\"><strong>Overall Accuracy</strong></td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\" colspan=\"2\"><strong>54.4% (1,319 / 2,425)</strong></td></tr></tbody></table><p><strong>Per-Sample Prediction (Sliding Window Vote):</strong></p><img src=\"/api/assets/ps_hlhr_p1.png\" alt=\"Per-sample HLHR p1\" style=\"max-width:100%; margin:12px 0;\"/><img src=\"/api/assets/ps_hlhr_p2.png\" alt=\"Per-sample HLHR p2\" style=\"max-width:100%; margin:12px 0;\"/><p><strong>분석:</strong> 3회 실험 중 가장 높은 정확도 <strong>54.4%</strong> 달성. FR 데이터를 제외하고 뒷다리에 집중함으로써 Normal의 recall이 28% -> 52%로 대폭 개선. HR(오른쪽 뒷다리)은 71%로 양호한 인식률을 보이나, HL(왼쪽 뒷다리)은 36%가 Normal로 오분류되는 경향이 있음.</p><hr/><h2>6. 실험 결과 비교 종합</h2><table style=\"border-collapse:collapse; width:100%; margin:16px 0;\"><thead><tr style=\"background:#f3f4f6;\"><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">실험</th><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">모드</th><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">클래스</th><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">Overall Acc</th><th style=\"border:1px solid #d1d5db; padding:8px 12px; text-align:left;\">특이사항</th></tr></thead><tbody><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Run 1 (0130)</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">downsample</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Normal/FR/HI</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\"><strong>42.1%</strong></td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">다운샘플링 없음, HI 편향 심각</td></tr><tr><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Run 2 (0200)</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">downsample</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Normal/FR/HI</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\"><strong>49.2%</strong></td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Normal 다운샘플링 적용, +7%p</td></tr><tr style=\"background:#d1fae5;\"><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Run 3 (0215)</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">hlhr</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">Normal/HL/HR</td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\"><strong>54.4%</strong></td><td style=\"border:1px solid #d1d5db; padding:8px 12px;\">FR 제외, 뒷다리 좌/우 세분화</td></tr></tbody></table><h2>7. 주요 관찰 및 인사이트</h2><ol><li><strong>클래스 불균형 문제:</strong> 모든 실험에서 다수 클래스(HI 또는 HR)로 편향되는 경향이 관찰됨. Class weight를 적용하였으나 충분하지 않음.</li><li><strong>FR 클래스의 어려움:</strong> 앞다리 이상(FR)은 모든 실험에서 가장 낮은 recall을 보임 (14~24%). 앞다리 파행의 포즈 패턴이 뒷다리에 비해 덜 뚜렷할 가능성.</li><li><strong>HLHR 모드의 우수성:</strong> FR을 제외하고 뒷다리에 집중하니 Normal recall이 28% -> 52%로 대폭 개선. 문제 범위를 좁히는 것이 효과적.</li><li><strong>HR vs HL 비대칭:</strong> HR(오른쪽)이 71%로 HL(왼쪽) 50%보다 높음. 좌우 반전 augmentation을 적용했음에도 비대칭 존재. 데이터 분포 차이 또는 포즈 추출 편향 가능성.</li><li><strong>Per-Sample Vote 패턴:</strong> 슬라이딩 윈도우 투표 결과, 일부 샘플은 높은 확신으로 정분류되나 경계 사례(borderline)에서 예측 분포가 혼재됨.</li></ol><h2>8. 향후 과제</h2><ul><li>Focal Loss, Label Smoothing 등 클래스 불균형 대응 기법 추가 실험</li><li>앞다리(FR) 전용 모델 분리 학습 검토</li><li>Transformer 기반 모델(legacy에 존재)과의 성능 비교</li><li>포즈 정규화 방식 개선 (회전 보정 로버스트니스 강화)</li><li>테스트 데이터 확대 (현재 19+ 환자로 제한적)</li><li>Per-sample 투표 임계값 최적화</li></ul><hr/><p style=\"color:#6b7280; font-size:0.9em;\">작성일: 2026-02-23 | Project: Dog Lameness Detection (DogLameness-3class-LSTM) | 5-Fold Cross Validation | Device: CUDA</p>",
  "date": "2026-02-23T00:00:00.000Z"
}